{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = 'Data/' #Путь к данным определяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Размеры изображения\n",
    "img_width, img_height = 150, 150\n",
    "# Размерность тензора на основе изображения для входных данных в нейронную сеть\n",
    "# backend Tensorflow, channels_last\n",
    "input_shape = (img_width, img_height, 3)\n",
    "# Количество эпох\n",
    "epochs = 30\n",
    "# Размер мини-выборки. Будем брать в каждой эпохе будем рассматривать 64 изображения\n",
    "batch_size = 64\n",
    "# Количество изображений для обучения\n",
    "nb_train_samples = 832\n",
    "# Количество изображений для проверки\n",
    "nb_validation_samples = 332\n",
    "# Количество изображений для тестирования\n",
    "nb_test_samples = 332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#150*150 разбивается на 32 части\n",
    "# 32 нейрона = 32 признака, 1 нерон выдит 3*3 пикселей\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# преобразует из двумерного в одномерное представленние\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#50 процентов (случайно) нейронов будет выключать в эпохе. Защита от переучивания сети\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#4 категории\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255) #Делит значения пикселя на 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 556 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(#генератор для уобучения. Как доставать эти изображения\n",
    "    images_path+'train/',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 124 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = datagen.flow_from_directory(#генератор для ваилидации\n",
    "    images_path+'val/',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 127 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_directory(#генератор для тестов.\n",
    "    images_path+'test',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "13/13 [==============================] - 37s 3s/step - loss: 1.1199 - accuracy: 0.5354 - val_loss: 0.6056 - val_accuracy: 0.8077\n",
      "Epoch 2/30\n",
      "13/13 [==============================] - 32s 2s/step - loss: 0.5489 - accuracy: 0.7672 - val_loss: 0.2504 - val_accuracy: 0.9519\n",
      "Epoch 3/30\n",
      "13/13 [==============================] - 34s 3s/step - loss: 0.3161 - accuracy: 0.9150 - val_loss: 0.0702 - val_accuracy: 0.9872\n",
      "Epoch 4/30\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.1652 - accuracy: 0.9557 - val_loss: 0.0204 - val_accuracy: 0.9936\n",
      "Epoch 5/30\n",
      "13/13 [==============================] - 32s 2s/step - loss: 0.1199 - accuracy: 0.9715 - val_loss: 0.0191 - val_accuracy: 0.9904\n",
      "Epoch 6/30\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0844 - accuracy: 0.9844 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0637 - accuracy: 0.9823 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "13/13 [==============================] - 32s 2s/step - loss: 0.0435 - accuracy: 0.9901 - val_loss: 5.2609e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0391 - accuracy: 0.9886 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "13/13 [==============================] - 32s 2s/step - loss: 0.0449 - accuracy: 0.9852 - val_loss: 9.2808e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "13/13 [==============================] - 34s 3s/step - loss: 0.0438 - accuracy: 0.9899 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "13/13 [==============================] - 39s 3s/step - loss: 0.0481 - accuracy: 0.9912 - val_loss: 6.3934e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "13/13 [==============================] - 37s 3s/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 7.2121e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "13/13 [==============================] - 35s 3s/step - loss: 0.0264 - accuracy: 0.9951 - val_loss: 4.8750e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "13/13 [==============================] - 32s 2s/step - loss: 0.0222 - accuracy: 0.9899 - val_loss: 9.4997e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "13/13 [==============================] - 39s 3s/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 1.0250e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "13/13 [==============================] - 32s 2s/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 1.2116e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "13/13 [==============================] - 36s 3s/step - loss: 0.0298 - accuracy: 0.9914 - val_loss: 1.5954e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "13/13 [==============================] - 34s 3s/step - loss: 0.0317 - accuracy: 0.9901 - val_loss: 1.1706e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "13/13 [==============================] - 32s 2s/step - loss: 0.0149 - accuracy: 0.9975 - val_loss: 3.2639e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "13/13 [==============================] - 36s 3s/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 3.0117e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "13/13 [==============================] - 35s 3s/step - loss: 0.0187 - accuracy: 0.9924 - val_loss: 2.7360e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "13/13 [==============================] - 37s 3s/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 9.1683e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "13/13 [==============================] - 32s 2s/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 2.9691e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "13/13 [==============================] - 35s 3s/step - loss: 0.0238 - accuracy: 0.9937 - val_loss: 2.5623e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "13/13 [==============================] - 34s 3s/step - loss: 0.0168 - accuracy: 0.9963 - val_loss: 1.0809e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "13/13 [==============================] - 33s 3s/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 6.9809e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "13/13 [==============================] - 35s 3s/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 1.4935e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "13/13 [==============================] - 38s 3s/step - loss: 0.0111 - accuracy: 0.9975 - val_loss: 9.6892e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "13/13 [==============================] - 38s 3s/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 3.3037e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ed1906a240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем описание модели в формате json\n",
    "model_json = model.to_json()\n",
    "# Записываем модель в файл\n",
    "json_file = open(\"hack_model_150p_30epochs.json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"hack_model_150p_30epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аккуратность на тестовых данных: 98.43%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "\n",
    "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in glob('*.png'):\n",
    "    test_image = image.load_img(i, target_size = (150, 150))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = model.predict(test_image)\n",
    "    print(result)\n",
    "    #acc = model.evaluate(val_generator, verbose=0)\n",
    "    #print(acc)\n",
    "    if result[0][0] == 1:\n",
    "        prediction = 'asterisk'\n",
    "    elif result[0][1] == 1:\n",
    "        prediction = 'blade'\n",
    "    elif result[0][2] == 1:\n",
    "        prediction = 'gun'\n",
    "    elif result[0][3] == 1:\n",
    "        prediction ='knife'\n",
    "    print('prediction', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
